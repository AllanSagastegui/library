# Audit Service: A Reactive Microservice with Elasticsearch

Welcome to the Audit Service, a modern, reactive microservice built with Spring Boot and designed according to the principles of Hexagonal Architecture. This service provides a robust and scalable solution for managing and querying audit logs generated by various services, using Elasticsearch as its data store.

## Project Overview

The Audit Service is a central component of a distributed system, responsible for handling all audit log-related operations. It is built on a fully reactive stack, ensuring high performance, resilience, and efficient resource utilization. The service exposes a RESTful API for retrieving audit logs and consumes events from a Kafka topic to create new log entries. It registers with a Eureka server for service discovery.

## Architectural Design: Hexagonal Architecture

This project implements the **Hexagonal (Ports and Adapters) Architecture** to ensure a clear separation of concerns and to isolate the core business logic from external technologies and frameworks.

-   **`domain`**: The heart of the application. It contains the core business models, logic, and the "ports" (interfaces) that define the contract for external interactions. This module is completely independent of any framework or external system.

-   **`application`**: This module orchestrates the business logic. It implements the input ports defined in the `domain` and uses the output ports to interact with external systems.

-   **`infrastructure`**: This layer contains the "adapters" that implement the ports defined in the `domain`. It is responsible for all external interactions.
    -   **`entry-points`**: Adapters that handle incoming requests.
        -   `reactive-web`: A Spring WebFlux-based REST API for querying audit logs.
        -   `kafka-listener`: Consumes events from a Kafka topic to create audit logs.
    -   **`driven-adapters`**: Adapters that interact with external services.
        -   `persistence`: Implements the repository interfaces using Spring Data Elasticsearch Reactive.
        -   `logger`: Provides a centralized logging mechanism.
        -   `aop`: Implements cross-cutting concerns using Aspect-Oriented Programming.

## Key Features

-   **Reactive and Non-Blocking:** Built with Spring WebFlux and Project Reactor for a fully asynchronous and non-blocking execution model.
-   **Event-Driven:** Consumes events from Apache Kafka to process audit logs asynchronously.
-   **Service Discovery:** Registers with Eureka for dynamic service discovery.
-   **Audit Log Management:** Provides RESTful endpoints for querying audit logs.
-   **Search and Analytics Engine:** Uses Spring Data Elasticsearch Reactive for reactive database access to an Elasticsearch cluster.
-   **API Documentation:** Automatically generates interactive API documentation with Springdoc OpenAPI.
-   **Clean Architecture:** Follows the Hexagonal Architecture for maintainability and testability.

## Technology Stack

-   **Frameworks:** Spring Boot 3, Spring WebFlux, Spring Data Elasticsearch Reactive, Spring Cloud
-   **Programming Language:** Java 17
-   **Reactive Programming:** Project Reactor
-   **Database:** Elasticsearch
-   **Messaging:** Apache Kafka
-   **Service Discovery:** Eureka
-   **Build Tool:** Gradle
-   **API Documentation:** Springdoc OpenAPI
-   **Utilities:** Lombok, MapStruct

## API Documentation

The API is documented using OpenAPI 3. Once the application is running, you can access the interactive Swagger UI at:

[http://localhost:8080/swagger-ui.html](http://localhost:8080/swagger-ui.html)

## Getting Started

### Prerequisites

-   JDK 17 or later
-   Gradle 8.x
-   Docker and Docker Compose

### 1. Build the Project

Clone the repository and build the project using the Gradle wrapper:

```bash
./gradlew build
```

### 2. Run External Services with Docker

The required external services (Elasticsearch, Kafka, and Eureka) can be started using the provided Docker Compose file:

```bash
docker-compose -f deployment/docker-compose.yml up -d
```

### 3. Configure the Application

The application is configured using environment variables. The following variables are required:

-   `ADAPTERS_PERSISTENCE_HOST`: The hostname of the Elasticsearch cluster.
-   `ADAPTERS_PERSISTENCE_PORT`: The port of the Elasticsearch cluster.
-   `ENTRY_POINTS_KAFKA_CONSUMER_BOOTSTRAP_SERVERS`: The address of the Kafka broker (e.g., `localhost:9094`).
-   `ENTRY_POINTS_KAFKA_CONSUMER_GROUP_ID`: The Kafka consumer group ID.
-   `ENTRY_POINTS_KAFKA_AUDIT_TOPIC`: The name of the topic to consume audit logs from.
-   `EUREKA_CLIENT_SERVICE_URL_DEFAULTZONE`: The URL of the Eureka server (e.g., `http://localhost:8761/eureka/`).
-   `CORS_ALLOWED_ORIGINS`: Comma-separated list of allowed origins for CORS (e.g., `http://localhost:4200,http://localhost:8080`).

You can set these variables in your environment or create a `.env` file in the project root.

### 4. Run the Application

Once the services are running and the environment is configured, you can start the application:

```bash
./gradlew bootRun
```

The service will be available at `http://localhost:8080`.

## Running Tests

To run the unit and integration tests, use the following command:

```bash
./gradlew test
```

## Deployment

The project includes a `Dockerfile` for building a container image of the service. You can build the image with the following command:

```bash
docker build -t audit-service .
```

The service can then be deployed to any container orchestration platform, such as Kubernetes or Docker Swarm.

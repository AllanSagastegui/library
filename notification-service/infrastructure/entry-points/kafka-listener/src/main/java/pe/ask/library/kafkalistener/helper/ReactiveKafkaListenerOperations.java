package pe.ask.library.kafkalistener.helper;

import com.fasterxml.jackson.databind.ObjectMapper;
import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.boot.context.event.ApplicationStartedEvent;
import org.springframework.context.event.EventListener;
import org.springframework.kafka.core.reactive.ReactiveKafkaConsumerTemplate;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;
import reactor.core.scheduler.Schedulers;

@Slf4j
@RequiredArgsConstructor
public abstract class ReactiveKafkaListenerOperations<T> {

    private final ReactiveKafkaConsumerTemplate<String, String> reactiveKafkaConsumer;
    private final ObjectMapper mapper;

    protected abstract String getTargetTopic();
    protected abstract Class<T> getPayloadClass();
    protected abstract Mono<Void> processRecord(T payload);

    @EventListener(ApplicationStartedEvent.class)
    public Flux<Void> listenMessage() {
        return reactiveKafkaConsumer
                .receiveAutoAck()
                // 1. Log cuando la aplicaciÃ³n arranca y se suscribe
                .doOnSubscribe(subscription -> log.info("âš¡ [KAFKA-LISTENER] Iniciando suscripciÃ³n al tÃ³pico: {}", getTargetTopic()))
                .filter(payload -> getTargetTopic().equals(payload.topic()))
                // 2. Log cuando llega el mensaje crudo (Raw JSON)
                .doOnNext(record -> log.info("ðŸ“© [KAFKA-RECEIVE] Mensaje recibido en {}: \nPayload: {}", record.topic(), record.value()))
                .publishOn(Schedulers.boundedElastic())
                .flatMap(record ->
                        Mono.fromCallable(() -> {
                                    // 3. Intento de deserializaciÃ³n
                                    log.debug("âš™ï¸ [KAFKA-DESERIALIZE] Convirtiendo mensaje a {}", getPayloadClass().getSimpleName());
                                    return mapper.readValue(record.value(), getPayloadClass());
                                })
                                .subscribeOn(Schedulers.boundedElastic())
                                .flatMap(payload -> {
                                    // 4. Antes de ejecutar tu lÃ³gica de negocio
                                    log.info("ðŸš€ [KAFKA-PROCESS] Ejecutando processRecord para: {}", payload);
                                    return processRecord(payload);
                                })
                                // 5. Log de Ã©xito tras terminar processRecord
                                .doOnSuccess(unused -> log.info("âœ… [KAFKA-SUCCESS] Mensaje procesado correctamente en {}", getTargetTopic()))
                )
                .doOnError(error -> log.error("âŒ [KAFKA-ERROR] Error procesando registro Kafka en tÃ³pico {}", getTargetTopic(), error))
                .retry()
                .repeat()
                .doOnSubscribe(s -> log.info("ðŸ”Œ [KAFKA-CONN] Flujo reactivo conectado."));
    }
}